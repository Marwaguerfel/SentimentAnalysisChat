# Sentiment Analysis Chatbot Documentation

## Table of Contents
1. [Project Overview](#project-overview)
2. [Installation](#installation)
3. [Project Structure](#project-structure)
4. [Core Features](#core-features)
5. [API Documentation](#api-documentation)
6. [Configuration](#configuration)
7. [Usage Examples](#usage-examples)
8. [Troubleshooting](#troubleshooting)

## Project Overview

A real-time chatbot system that combines BERT-based sentiment analysis with OpenAI's GPT-3.5 for generating contextual responses. The system maintains conversation memory and provides conversation summaries.

### Key Features
- Real-time sentiment analysis using BERT
- Contextual responses using OpenAI GPT-3.5
- Conversation memory management
- Conversation summarization
- Web interface with real-time updates

## Installation

### Prerequisites
- Python 3.8+
- PyTorch
- CUDA (optional, for GPU support)

### Step 1: Clone the Repository
```bash
git clone <repository-url>
cd sentiment-chatbot
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

Required packages:
```txt
flask
flask-cors
torch
transformers
nltk
openai
```

### Step 3: Set Up Model Files
Place BERT model files in `./bert_sentiment_model/`:
- config.json
- model.safetensors
- tokenizer_config.json
- vocab.txt
- special_tokens_map.json
- training_args.bin

### Step 4: Configure OpenAI API
Create a `key.py` file:
```python
OPENAI_API_KEY = 'your-api-key-here'
```

## Project Structure

```
sentiment-chatbot/
├── app.py              # Main application file
├── key.py             # API key configuration
├── requirements.txt    # Project dependencies
├── bert_sentiment_model/
│   ├── config.json
│   ├── model.safetensors
│   └── ...
└── templates/
    └── index.html     # Web interface
```

## Core Features

### Sentiment Analysis
```python
def process_text(text):
    """
    Processes text to determine sentiment
    Returns: Dict with sentiment, confidence, and scores
    """
```
- Cleans and preprocesses text
- Uses BERT model for sentiment analysis
- Returns sentiment classification with confidence scores

### Conversation Management
```python
def manage_conversation(session_id, role, content, sentiment=None):
    """
    Manages conversation history and sentiment tracking
    """
```
- Maintains conversation history
- Tracks sentiment trends
- Manages memory limits

### AI Response Generation
```python
def get_ai_response(session_id, user_message, sentiment_info):
    """
    Generates contextual responses using OpenAI
    """
```
- Utilizes conversation history
- Incorporates sentiment context
- Provides fallback responses

## API Documentation

### Endpoints

#### 1. GET /
- Returns the web interface
- Response: HTML page

#### 2. POST /chat
- Processes chat messages and returns responses
- Request Body:
```json
{
    "text": "user message",
    "session_id": "unique_session_id"
}
```
- Response:
```json
{
    "response": "bot response",
    "sentiment": "positive/neutral/negative",
    "confidence": 0.95,
    "additional_info": {
        "positive": 0.8,
        "neutral": 0.15,
        "negative": 0.05
    }
}
```

#### 3. POST /summarize
- Generates conversation summaries
- Request Body:
```json
{
    "session_id": "unique_session_id"
}
```
- Response:
```json
{
    "summary": "conversation summary",
    "type": "conversation"
}
```

## Configuration

### Memory Settings
```python
MAX_MEMORY = 10  # Maximum number of messages to keep in memory
```

### Model Configuration
```python
MODEL_PATH = "./bert_sentiment_model"
```

### OpenAI Settings
```python
client = OpenAI(api_key=OPENAI_API_KEY)
```

## Usage Examples

### Starting the Server
```bash
python app.py
```
The server will start on `http://localhost:5000`

### Making API Requests

#### Chat Request
```python
import requests

response = requests.post('http://localhost:5000/chat', 
    json={
        'text': 'Hello, how are you?',
        'session_id': 'user123'
    }
)
print(response.json())
```

#### Summary Request
```python
response = requests.post('http://localhost:5000/summarize',
    json={
        'session_id': 'user123'
    }
)
print(response.json())
```



Please follow these guidelines when contributing:
1. Create feature branches
2. Write descriptive commit messages
3. Add tests for new features
4. Update documentation

## License

This project is licensed under the MIT License - see the LICENSE file for details.